{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Prediction Model - Google Colab Version\n",
    "\n",
    "This notebook trains age classification models (MobileNetV2, ResNet50, EfficientNet) on the Faces Age Detection Dataset.\n",
    "\n",
    "## Setup Instructions\n",
    "1. Go to Runtime > Change runtime type > Select **T4 GPU**\n",
    "2. Run the cells below in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Setup Kaggle API\n\nTo download the dataset, you need your Kaggle API credentials:\n1. Go to https://www.kaggle.com/settings\n2. Scroll to \"API\" section and click \"Create New Token\"\n3. This downloads `kaggle.json` - upload it when prompted below"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Upload your kaggle.json file\nfrom google.colab import files\nimport os\n\n# Create kaggle directory\nos.makedirs('/root/.kaggle', exist_ok=True)\n\n# Upload kaggle.json\nprint(\"Please upload your kaggle.json file:\")\nuploaded = files.upload()\n\n# Move to correct location\n!mv kaggle.json /root/.kaggle/\n!chmod 600 /root/.kaggle/kaggle.json\nprint(\"Kaggle API configured!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from Kaggle\n",
    "!kaggle datasets download -d arashnic/faces-age-detection-dataset\n",
    "!unzip -q faces-age-detection-dataset.zip -d /content/dataset\n",
    "!rm faces-age-detection-dataset.zip\n",
    "print(\"Dataset downloaded and extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "!ls -la /content/dataset\n",
    "!echo \"---\"\n",
    "!ls -la /content/dataset/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Dataset Loading\n",
    "\n",
    "This dataset has two parts. We'll use the UTKFace portion which has age in the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory - adjust based on the actual structure after extraction\n",
    "# The UTKFace images should have filenames like: age_gender_race_datetime.jpg\n",
    "DATA_DIR = \"/content/dataset\"\n",
    "\n",
    "class AgeDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Define age groups\n",
    "        def categorize_age(age):\n",
    "            if 0 <= age <= 25: return 0\n",
    "            elif 26 <= age <= 50: return 1\n",
    "            elif 51 <= age <= 75: return 2\n",
    "            elif 76 <= age <= 116: return 3\n",
    "            return -1\n",
    "\n",
    "        # Find all image files recursively\n",
    "        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
    "        all_images = []\n",
    "        for ext in image_extensions:\n",
    "            all_images.extend(glob.glob(os.path.join(data_dir, '**', ext), recursive=True))\n",
    "        \n",
    "        print(f\"Found {len(all_images)} total images\")\n",
    "        \n",
    "        # Process each image\n",
    "        for img_path in all_images:\n",
    "            filename = os.path.basename(img_path)\n",
    "            if filename.startswith('.'): \n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Try to extract age from filename (format: age_gender_race_datetime.jpg)\n",
    "                age = int(filename.split('_')[0])\n",
    "                grouped_label = categorize_age(age)\n",
    "                if grouped_label != -1:\n",
    "                    self.files.append(img_path)\n",
    "                    self.labels.append(grouped_label)\n",
    "            except (ValueError, IndexError):\n",
    "                # Skip files that don't match the expected format\n",
    "                continue\n",
    "        \n",
    "        print(f\"Loaded {len(self.files)} valid images with age labels\")\n",
    "        \n",
    "        # Print class distribution\n",
    "        from collections import Counter\n",
    "        dist = Counter(self.labels)\n",
    "        print(f\"Class distribution: {dict(sorted(dist.items()))}\")\n",
    "        print(\"  0: Age 0-25, 1: Age 26-50, 2: Age 51-75, 3: Age 76-116\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transforms_dict = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load dataset and split\n",
    "full_dataset = AgeDataset(DATA_DIR, transform=transforms_dict[\"train\"])\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"\\nDataset splits: Train={train_size}, Val={val_size}, Test={test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2),\n",
    "    \"val\": DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2),\n",
    "    \"test\": DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2),\n",
    "}\n",
    "print(\"DataLoaders created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == \"mobilenet_v2\":\n",
    "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "    \n",
    "    elif model_name == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "\n",
    "    elif model_name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name!\")\n",
    "\n",
    "    # Freeze feature extractor\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Train new classifier layers\n",
    "    if \"efficientnet\" in model_name or \"mobilenet\" in model_name:\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, model_name, num_epochs=10):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), f\"best_{model_name}.pth\")\n",
    "\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, model_name):\n",
    "    model.load_state_dict(torch.load(f\"best_{model_name}.pth\", weights_only=True))\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "    print(f\"Test Accuracy for {model_name}: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(model, dataloader, model_name):\n",
    "    model.load_state_dict(torch.load(f\"best_{model_name}.pth\", weights_only=True))\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['0-25', '26-50', '51-75', '76-116'], \n",
    "                yticklabels=['0-25', '26-50', '51-75', '76-116'])\n",
    "    plt.xlabel(\"Predicted Age Group\")\n",
    "    plt.ylabel(\"True Age Group\")\n",
    "    plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MobileNetV2\n",
    "model_name = \"mobilenet_v2\"\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Training {model_name}...\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "model = get_model(model_name)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "model = train_model(model, dataloaders, criterion, optimizer, model_name, num_epochs=10)\n",
    "test_model(model, dataloaders[\"test\"], model_name)\n",
    "plot_confusion_matrix(model, dataloaders[\"test\"], model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet50\n",
    "model_name = \"resnet50\"\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Training {model_name}...\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "model = get_model(model_name)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "model = train_model(model, dataloaders, criterion, optimizer, model_name, num_epochs=10)\n",
    "test_model(model, dataloaders[\"test\"], model_name)\n",
    "plot_confusion_matrix(model, dataloaders[\"test\"], model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EfficientNet-B0\n",
    "model_name = \"efficientnet_b0\"\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Training {model_name}...\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "model = get_model(model_name)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "model = train_model(model, dataloaders, criterion, optimizer, model_name, num_epochs=10)\n",
    "test_model(model, dataloaders[\"test\"], model_name)\n",
    "plot_confusion_matrix(model, dataloaders[\"test\"], model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Grad-CAM Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def denormalize_image(image_tensor):\n",
    "    \"\"\"Convert a normalized tensor image back to its original form for visualization\"\"\"\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    image = image_tensor.cpu().detach().numpy().transpose(1, 2, 0)\n",
    "    image = (image * std) + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    return (image * 255).astype(np.uint8)\n",
    "\n",
    "def grad_cam(model, image_tensor, target_layer, class_idx=None):\n",
    "    model.eval()\n",
    "    gradients = None\n",
    "    activations = None\n",
    "    \n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        nonlocal gradients\n",
    "        gradients = grad_output[0]\n",
    "    \n",
    "    def forward_hook(module, input, output):\n",
    "        nonlocal activations\n",
    "        activations = output\n",
    "    \n",
    "    # Register hooks\n",
    "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
    "    backward_handle = target_layer.register_full_backward_hook(backward_hook)\n",
    "    \n",
    "    # Ensure image_tensor requires gradient\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device).requires_grad_(True)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(image_tensor)\n",
    "    \n",
    "    if class_idx is None:\n",
    "        class_idx = output.argmax().item()\n",
    "    \n",
    "    # Backpropagate\n",
    "    model.zero_grad()\n",
    "    loss = output[0, class_idx]\n",
    "    loss.backward()\n",
    "    \n",
    "    # Remove hooks\n",
    "    forward_handle.remove()\n",
    "    backward_handle.remove()\n",
    "    \n",
    "    if gradients is None:\n",
    "        raise ValueError(\"Gradients were not captured. Check if target_layer is correct.\")\n",
    "    \n",
    "    # Compute Grad-CAM\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    for i in range(activations.shape[1]):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "    heatmap = torch.mean(activations, dim=1).squeeze().cpu().detach().numpy()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap) + 1e-8\n",
    "    \n",
    "    # Convert heatmap to color\n",
    "    heatmap = cv2.resize(heatmap, (224, 224))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Convert original image using denormalization\n",
    "    original_image = denormalize_image(image_tensor.squeeze(0))\n",
    "    \n",
    "    # Blend heatmap with original image\n",
    "    superimposed_img = cv2.addWeighted(original_image, 0.6, heatmap, 0.4, 0)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_name):\n",
    "    model = get_model(model_name)\n",
    "    model.load_state_dict(torch.load(f\"best_{model_name}.pth\", weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    if model_name == \"resnet50\":\n",
    "        target_layer = model.layer4[-1].conv3\n",
    "    elif model_name == \"mobilenet_v2\":\n",
    "        target_layer = model.features[-1][0]\n",
    "    elif model_name == \"efficientnet_b0\":\n",
    "        target_layer = model.features[-1][0]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name!\")\n",
    "\n",
    "    return model, target_layer\n",
    "\n",
    "def apply_grad_cam_to_images(model, target_layer, num_images=10):\n",
    "    sample_images = [test_dataset[i][0] for i in range(num_images)]\n",
    "    for i, image in enumerate(sample_images):\n",
    "        print(f\"Grad-CAM for Test Image {i+1}\")\n",
    "        grad_cam(model, image, target_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Grad-CAM for each model\n",
    "for model_name in [\"mobilenet_v2\", \"resnet50\", \"efficientnet_b0\"]:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Applying Grad-CAM for {model_name}...\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    model, target_layer = load_trained_model(model_name)\n",
    "    apply_grad_cam_to_images(model, target_layer, num_images=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}