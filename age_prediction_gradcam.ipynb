{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": "# Facial Age Prediction with Deep Learning\n\nThis notebook implements facial age classification using transfer learning with three CNN architectures:\n- **MobileNetV2**\n- **ResNet50** \n- **EfficientNet-B0**\n\nIncludes Grad-CAM visualizations for model interpretability.\n\n## Setup"
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom PIL import Image\nimport os",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": "# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# =============================================================================\n# UPDATE THIS PATH to your dataset location\n# Dataset: https://www.kaggle.com/datasets/arashnic/faces-age-detection-dataset\n# =============================================================================\ndata_dir = \"./data/face-images\"  # Update this path\n\nclass AgeDataset(Dataset):\n    \"\"\"Custom dataset for age classification from facial images.\"\"\"\n    \n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.files = []\n        self.labels = []\n\n        def categorize_age(age):\n            \"\"\"Categorize age into 4 groups.\"\"\"\n            if 0 <= age <= 25: return 0    # Young\n            elif 26 <= age <= 50: return 1  # Adult\n            elif 51 <= age <= 75: return 2  # Middle-aged\n            elif 76 <= age <= 116: return 3 # Senior\n            return -1\n\n        # Iterate over each part directory\n        for part in [\"part1\", \"part2\", \"part3\"]:\n            part_path = os.path.join(data_dir, part)\n            if not os.path.exists(part_path):\n                continue\n            for filename in os.listdir(part_path):\n                if filename.startswith(\".\"):\n                    continue\n\n                try:\n                    label = int(filename.split('_')[0])\n                    grouped_label = categorize_age(label)\n                    if grouped_label != -1:\n                        self.files.append(os.path.join(part_path, filename))\n                        self.labels.append(grouped_label)\n                except ValueError:\n                    continue\n        \n        print(f\"Loaded {len(self.files)} images\")\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        img_path = self.files[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\n# Define transformations\ntransforms_dict = {\n    \"train\": transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ]),\n    \"val\": transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ]),\n    \"test\": transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ]),\n}\n\n# Load dataset and split (70/15/15)\nfull_dataset = AgeDataset(data_dir, transform=transforms_dict[\"train\"])\ntrain_size = int(0.7 * len(full_dataset))\nval_size = int(0.15 * len(full_dataset))\ntest_size = len(full_dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n\nprint(f\"Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n\n# Data loaders\ndataloaders = {\n    \"train\": DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2),\n    \"val\": DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2),\n    \"test\": DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2),\n}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load different models\n",
    "def get_model(model_name):\n",
    "    if model_name == \"mobilenet_v2\":\n",
    "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "    \n",
    "    elif model_name == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "\n",
    "    elif model_name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name!\")\n",
    "\n",
    "    # Freeze feature extractor\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Train new classifier layers\n",
    "    if \"efficientnet\" in model_name or \"mobilenet\" in model_name:\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, dataloaders, criterion, optimizer, model_name, num_epochs=10):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval() # turns of some layers that shouldnt be active during evaluation - we dont want to run drop off\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), f\"best_{model_name}.pth\")\n",
    "\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test_model(model, dataloader, model_name):\n",
    "    model.load_state_dict(torch.load(f\"best_{model_name}.pth\", weights_only=True))\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "    print(f\"Test Accuracy for {model_name}: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(model, dataloader, model_name):\n",
    "    model.load_state_dict(torch.load(f\"best_{model_name}.pth\", weights_only=True))\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "print(f\"\\nTraining {model_name}...\\n\")\n",
    "model = get_model(model_name)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "model = train_model(model, dataloaders, criterion, optimizer, model_name, num_epochs=10)\n",
    "test_model(model, dataloaders[\"test\"], model_name)\n",
    "\n",
    "plot_confusion_matrix(model, dataloaders[\"test\"], model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet50\"\n",
    "print(f\"\\nTraining {model_name}...\\n\")\n",
    "model = get_model(model_name)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "model = train_model(model, dataloaders, criterion, optimizer, model_name, num_epochs=10)\n",
    "test_model(model, dataloaders[\"test\"], model_name)\n",
    "\n",
    "plot_confusion_matrix(model, dataloaders[\"test\"], model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"efficientnet_b0\"\n",
    "print(f\"\\nTraining {model_name}...\\n\")\n",
    "model = get_model(model_name)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "model = train_model(model, dataloaders, criterion, optimizer, model_name, num_epochs=10)\n",
    "test_model(model, dataloaders[\"test\"], model_name)\n",
    "\n",
    "plot_confusion_matrix(model, dataloaders[\"test\"], model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def denormalize_image(image_tensor):\n",
    "    \"\"\" Convert a normalized tensor image back to its original form for visualization \"\"\"\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    image = image_tensor.cpu().detach().numpy().transpose(1, 2, 0) \n",
    "    image = (image * std) + mean  # De-normalize\n",
    "    image = np.clip(image, 0, 1)  # Clip to valid range [0,1]\n",
    "    return (image * 255).astype(np.uint8)  # Convert to 8-bit format\n",
    "\n",
    "# Grad-CAM Implementation\n",
    "def grad_cam(model, image_tensor, target_layer, class_idx=None):\n",
    "    model.eval()\n",
    "    gradients = None\n",
    "    activations = None\n",
    "    \n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        nonlocal gradients\n",
    "        gradients = grad_output[0]\n",
    "    \n",
    "    def forward_hook(module, input, output):\n",
    "        nonlocal activations\n",
    "        activations = output\n",
    "    \n",
    "    # Register hooks\n",
    "    target_layer.register_forward_hook(forward_hook)\n",
    "    target_layer.register_full_backward_hook(backward_hook)\n",
    "    \n",
    "    # Ensure image_tensor requires gradient\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device).requires_grad_(True)  \n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(image_tensor)\n",
    "    \n",
    "    if class_idx is None:\n",
    "        class_idx = output.argmax().item()\n",
    "    \n",
    "    # Backpropagate\n",
    "    model.zero_grad()\n",
    "    loss = output[0, class_idx]\n",
    "    loss.backward()\n",
    "    \n",
    "    if gradients is None:\n",
    "        raise ValueError(\"Gradients were not captured. Check if target_layer is correct.\")\n",
    "    \n",
    "    # Compute Grad-CAM\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    for i in range(activations.shape[1]):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "    heatmap = torch.mean(activations, dim=1).squeeze().cpu().detach().numpy()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)  # Normalize between 0 and 1\n",
    "    \n",
    "    # Convert heatmap to color\n",
    "    heatmap = cv2.resize(heatmap, (224, 224))  # Resize to match original image size\n",
    "    heatmap = np.uint8(255 * heatmap)  # Scale between 0-255\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)  # Apply colormap\n",
    "    \n",
    "    # Convert original image using denormalization\n",
    "    original_image = denormalize_image(image_tensor.squeeze(0))  \n",
    "    \n",
    "    # Blend heatmap with original image\n",
    "    superimposed_img = cv2.addWeighted(original_image, 0.6, heatmap, 0.4, 0)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model once\n",
    "def load_trained_model(model_name):\n",
    "    model = get_model(model_name)\n",
    "    model.load_state_dict(torch.load(f\"best_{model_name}.pth\", weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    # Select only the Conv2d layer inside the last convolutional block\n",
    "    if model_name == \"resnet50\":\n",
    "        target_layer = model.layer4[-1].conv3  # Last conv layer\n",
    "    elif model_name == \"mobilenet_v2\":\n",
    "        target_layer = model.features[-1][0]  # Select only the Conv2d layer\n",
    "    elif model_name == \"efficientnet_b0\":\n",
    "        target_layer = model.features[-1][0]  # Select only the Conv2d layer\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name!\")\n",
    "\n",
    "    return model, target_layer\n",
    "\n",
    "# Apply Grad-CAM to multiple images\n",
    "def apply_grad_cam_to_images(model, target_layer, num_images=10):\n",
    "    sample_images = [test_dataset[i][0] for i in range(num_images)]  # Get test images\n",
    "    for i, image in enumerate(sample_images):\n",
    "        print(f\"Grad-CAM for Test Image {i+1}\")\n",
    "        grad_cam(model, image, target_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Grad-CAM for each model\n",
    "for model_name in [\"mobilenet_v2\", \"resnet50\", \"efficientnet_b0\"]:\n",
    "    print(f\"\\nApplying Grad-CAM for {model_name}...\\n\")\n",
    "    model, target_layer = load_trained_model(model_name)\n",
    "    apply_grad_cam_to_images(model, target_layer, num_images=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}